{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **FINAL PROJECT - Chocolate bar rating dataset**"
      ],
      "metadata": {
        "id": "AB5G87bTbNEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naama Kashani 312400476\n",
        "<p>\n",
        "Tal Ishon 315242297"
      ],
      "metadata": {
        "id": "eJvPj_Xg2y7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imports"
      ],
      "metadata": {
        "id": "okKqrHOUDCVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "!pip install  catboost\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from xgboost import plot_tree\n",
        "import shap\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "metadata": {
        "id": "TlWE8fVDbLlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75eb2399-5791-4768-d249-a4c583a84412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.10/dist-packages (from shap) (0.0.7)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data and check the shape\n"
      ],
      "metadata": {
        "id": "sABfKZ_iWW1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv( \"/content/chocolate_dataset.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "id": "YYlot7LqWbZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze the dataset**"
      ],
      "metadata": {
        "id": "T0-56wo84ZNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "TXhZHh7YRB5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are mixture of data types."
      ],
      "metadata": {
        "id": "rRIbpUPGVRGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#view few samples\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gtkUZIrYR5XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Viewing the data reveal the types, we can see numeric and textual data types."
      ],
      "metadata": {
        "id": "HjLggapRDdTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We renamed the column names to be more significant."
      ],
      "metadata": {
        "id": "SQntagQ9Dmnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## rename columns and replace % to be float number\n",
        "original_colnames = df.columns\n",
        "new_colnames = ['company', 'chocolate_bar_origin', 'REF', 'review_year', 'cocoa_p',\n",
        "                'company_location', 'rating', 'bean_type', 'bean_origin']\n",
        "df = df.rename(columns=dict(zip(original_colnames, new_colnames)))\n",
        "## And modify data types\n",
        "df['cocoa_p'] = df['cocoa_p'].str.replace('%','').astype(float)/100\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PMme625aSIJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column\n",
        "missing_per_column = df.isnull().any()\n",
        "\n",
        "# Filter the columns that contain missing values\n",
        "columns_with_missing_values = missing_per_column[missing_per_column]\n",
        "\n",
        "# Print the names of columns with missing values\n",
        "print(\"Columns with missing values:\")\n",
        "print(columns_with_missing_values.index.tolist())"
      ],
      "metadata": {
        "id": "W9mX_6hfS2g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values are identified within the \"bean type\" and \"broad bean origin (country)\" columns we will handel that issue.\n"
      ],
      "metadata": {
        "id": "53tDz0O2Vbry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set plot style\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Plot histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['rating'],  bins=30, color=\"lightblue\", edgecolor=\"black\")\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Ratings\")\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UsvU10OQVnmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of samples exhibit ratings within the 2.5 to 4 range. Imbalanced ratings characterize a non-uniform distribution across the dataset. This issue will be handled when predicting ratings."
      ],
      "metadata": {
        "id": "259hIyzgYspx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['bean_origin'].sort_values().unique())"
      ],
      "metadata": {
        "id": "nF2a3EMgZOEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've noticed that certain bean origins are labeled inconsistently, using different names. Additionally, there are instances where the bean origin comprises multiple locations in some samples. We'll need to address this through feature engineering by appropriately separating them.The same problem happens in chocolate_bar_origin column."
      ],
      "metadata": {
        "id": "sOMorlj34eTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've observed that the 'country' column contains free-form text that lacks consistency. To address this issue, we'll need to perform feature engineering on this column to standardize its values."
      ],
      "metadata": {
        "id": "MEgS9amedwtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text preparation (correction) func\n",
        "def txt_prep(text):\n",
        "    replacements = [\n",
        "        ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
        "        ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
        "        ['Mad,|Mad$', 'Madagascar, '],\n",
        "        ['PNG', 'Papua New Guinea, '],\n",
        "        ['Guat,|Guat$', 'Guatemala, '],\n",
        "        ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
        "        ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
        "        ['Nic,|Nic$', 'Nicaragua, '],\n",
        "        ['Cost Rica', 'Costa Rica'],\n",
        "        ['Mex,|Mex$', 'Mexico, '],\n",
        "        ['Jam,|Jam$', 'Jamaica, '],\n",
        "        ['Haw,|Haw$', 'Hawaii, '],\n",
        "        ['Gre,|Gre$', 'Grenada, '],\n",
        "        ['Tri,|Tri$', 'Trinidad, '],\n",
        "        ['C Am', 'Central America'],\n",
        "        ['S America', 'South America'],\n",
        "        [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
        "        [' Bali', ',Bali']\n",
        "    ]\n",
        "    for i, j in replacements:\n",
        "        text = re.sub(i, j, text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "6oX_ciCcyBvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data-preprocess**"
      ],
      "metadata": {
        "id": "sD-zwH5aMBXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the names in bean_origin consistent"
      ],
      "metadata": {
        "id": "jLZMAkgubsfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Replace bean_origin\n",
        "df['bean_origin'] = df['bean_origin'].astype(str)\n",
        "df['bean_origin'] = df['bean_origin'].str.replace('.', '').apply(txt_prep)"
      ],
      "metadata": {
        "id": "-B-Dl11QDykx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['company_location'].sort_values().unique())"
      ],
      "metadata": {
        "id": "0ZRgcpFbbQC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that in company_location column there are some values we need to rename."
      ],
      "metadata": {
        "id": "K199vQq9b10m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['company_location'] = df['company_location']\\\n",
        ".str.replace('Amsterdam', 'Holland')\\\n",
        ".str.replace('U.K.', 'England')\\\n",
        ".str.replace('Niacragua', 'Nicaragua')\\\n",
        ".str.replace('Domincan Republic', 'Dominican Republic')"
      ],
      "metadata": {
        "id": "7NUFUfz5bam1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Features preprocess**"
      ],
      "metadata": {
        "id": "8ZAd8d3dxrc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "asia = ['Japan', 'Vietnam', 'Israel', 'South Korea', 'Singapore', 'India', 'Philippines', 'Russia']\n",
        "africa = ['Madagascar', 'Sao Tome', 'South Africa', 'Ghana']\n",
        "north_america = ['U.S.A.', 'Canada', 'Martinique', 'Niacragua', 'Guatemala', 'St. Lucia', 'Puerto Rico', 'Mexico', 'Costa Rica', 'Honduras', 'Nicaragua', 'Domincan Republic', ]\n",
        "south_america = ['Ecuador', 'Eucador', 'Colombia', 'Suriname', 'Bolivia', 'Venezuela', 'Chile', 'Peru', 'Brazil', 'Argentina', 'Lithuania']\n",
        "europe = ['France', 'Denmark', 'Scotland', 'Wales', 'Czech Republic', 'Finland', 'Ireland', 'Portugal', 'Netherlands', 'Poland', 'Amsterdam', 'Sweden', 'U.K.', 'Italy', 'Belgium', 'Switzerland', 'Germany', 'Austria', 'Spain', 'Hungary', ]\n",
        "oceania = ['Australia', 'New Zealand', 'Fiji']\n",
        "def continents(x):\n",
        "    if x in asia:\n",
        "        return 'asia'\n",
        "    if x in africa:\n",
        "        return 'africa'\n",
        "    if x in north_america:\n",
        "        return 'north america'\n",
        "    if x in south_america:\n",
        "        return 'south america'\n",
        "    if x in europe:\n",
        "        return 'europe'\n",
        "    if x in oceania:\n",
        "        return 'oceania'\n",
        "    return 'europe'\n",
        "df['Continent'] = df['company_location'].apply(continents)\n",
        "df['Continent'].value_counts()\n",
        "plt.xticks(rotation=45)\n",
        "sns.countplot(x='Continent', data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lOseBl-hEOVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we add column of continent and we can see that most of the samples came from euorpe and north america."
      ],
      "metadata": {
        "id": "kMmwd6rfxzjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['chocolate_bar_origin'].value_counts()"
      ],
      "metadata": {
        "id": "sXNxtXdgxK6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['chocolate_bar_origin'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "1A1pt5JxyAIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We chose to drop that column because we think that it is not adding necessery information for the rating\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_bKQdjIGLbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['REF'].unique().shape"
      ],
      "metadata": {
        "id": "gg9GzUu-n01P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data visualizations**\n",
        "### After the pre-processing we applied on our data, let's visualize it and check if there is more processing needed in our data (such as dropping unnecessarily columns etc)\n",
        "\n"
      ],
      "metadata": {
        "id": "fnj6_hbZ4WgB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the distribution of bean_type when bean_origin is mixed."
      ],
      "metadata": {
        "id": "DP0AJnuacdrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for rows with multiple values in \"bean_origin\"\n",
        "filtered_df = df[df['bean_origin'].str.contains(',')].copy()  # Use copy() to create a copy of the DataFrame\n",
        "filtered_df.loc[:, 'bean_type'] = filtered_df['bean_type'].replace('\\xa0', \"Missing\")\n",
        "filtered_df.loc[:, 'bean_type'] = filtered_df['bean_type'].replace('nan', \"Missing\")\n",
        "# Look at distribution of bean_type\n",
        "fig, ax = plt.subplots(figsize=[10, 4])\n",
        "sns.countplot(data=filtered_df, x='bean_type', ax=ax)\n",
        "ax.set_title('Distribution of bean_type when bean_origin is mixed')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GIy0H78gL0mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we have multiple values in attribute “bean_origin” (mixed) we notice that the “bean_type” value is mostly ‘Blend’ or ‘missing’ or has more than one value in “bean_type”. (Maybe we could fill the missing values in “bean_type” to ‘blend’ according to this insight)."
      ],
      "metadata": {
        "id": "b-UHtpOMETkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "check the distribution of bean_type when bean_origin is missing"
      ],
      "metadata": {
        "id": "P42aZMiYc4iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_df = df[df['bean_origin'].isna() | (df['bean_origin'] == \" \")].copy()\n",
        "missing_df.loc[:, 'bean_type'] = missing_df['bean_type'].replace('\\xa0', \"Missing\")\n",
        "missing_df.loc[:, 'bean_type'] = missing_df['bean_type'].replace('nan', \"Missing\")\n",
        "fig, ax = plt.subplots(figsize=[10, 6])\n",
        "sns.countplot(data=missing_df, x='bean_type', ax=ax)\n",
        "ax.set_title('Distribution of bean_type when bean_origin is missing')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BJKkp3S1N7qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " When we have ‘missing’ in “bean_origin” it most likely means that the “bean_type” is either ‘Blend’ or ‘missing ’."
      ],
      "metadata": {
        "id": "aF9W8CDQNXrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['bean_type'].sort_values().unique())"
      ],
      "metadata": {
        "id": "VGmKqthqwGnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will handle missing values later."
      ],
      "metadata": {
        "id": "bryQxvtuyqB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['bean_origin'].value_counts()"
      ],
      "metadata": {
        "id": "sabvVfAWnMR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have many values in column 'bean_origin' we decieded to split each sample (row) according to the number of values in 'bean_origin' attribute.\n",
        "In order to do so, we first want to add a new column named 'weight' for each sample."
      ],
      "metadata": {
        "id": "kpV3YbAui6Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split values, calculate weights, and create new rows\n",
        "def split_and_duplicate(row):\n",
        "    origins = row['bean_origin'].split(',')\n",
        "    if len(origins) > 1:\n",
        "        duplicated_rows = []\n",
        "        weight = 1 / len(origins)  # Calculate weight for split samples\n",
        "        for origin in origins:\n",
        "            new_row = row.copy()\n",
        "            new_row['bean_origin'] = origin\n",
        "            new_row['weight'] = weight\n",
        "            duplicated_rows.append(new_row)\n",
        "        return duplicated_rows\n",
        "    else:\n",
        "        row['weight'] = 1\n",
        "        return [row]\n",
        "\n",
        "# Apply function to each row and concatenate results\n",
        "df_split = pd.concat([pd.DataFrame(split_and_duplicate(row)) for _, row in df.iterrows()], ignore_index=True)\n",
        "\n",
        "df_split"
      ],
      "metadata": {
        "id": "K-x8M4dVi53G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_split['weight'].value_counts()"
      ],
      "metadata": {
        "id": "h5nojTUloRX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the split df to the origin df\n",
        "df = df_split"
      ],
      "metadata": {
        "id": "97vZ364EEyVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bean_origin'].value_counts()"
      ],
      "metadata": {
        "id": "ROcJBjRstKCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Look at distribution of Cocoa %\n",
        "fig, ax = plt.subplots(figsize=[16,4])\n",
        "sns.distplot(df['cocoa_p'], ax=ax)\n",
        "ax.set_title('Cocoa %, Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6bll0uFf47t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that most of the bars have coca percent around 0.7"
      ],
      "metadata": {
        "id": "Lf1KkbvrH408"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_counts = df.bean_origin.value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(20, 5))\n",
        "sns.barplot(x=top_counts.index, y=top_counts.values, hue=top_counts.index, palette=\"Blues_r\", legend=False)\n",
        "plt.title(\"Where do most beans come from?\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.xlabel(\"bean_origin\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NeW3ZsBI42Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that most of the beans come from Africa and south America countries."
      ],
      "metadata": {
        "id": "dk1rAEwEHA7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we exam the best chocolate bar in a broader way, we will take the mean value of the chocolate bar ratings by grouping the origins and company locations. Then we will use the records greater or equal to 10"
      ],
      "metadata": {
        "id": "IvpqUIVofrYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by origin and location, and calculate average rating\n",
        "grouped = df.groupby(['bean_origin', 'company_location']).agg(count=('rating', 'count'), rate4=('rating', 'mean')).reset_index()\n",
        "\n",
        "# Filter out counts less than 20\n",
        "grouped = grouped[grouped['count'] >= 10]\n",
        "\n",
        "# Pivot the DataFrame to prepare for heatmap\n",
        "pivot_table = grouped.pivot(index='bean_origin', columns='company_location', values='rate4')\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(pivot_table, annot=False, cmap=\"RdYlGn\", linewidths=.5)\n",
        "plt.title('Chocolate Bar Heatmap')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Bean Origin')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VOo529wwerk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the heatmap we can see USA produces the most chocolate bars. Whereas Canda produced chocolate with cocao beans originated from Venezuela and Peru has the highest quality. This is consisted with our previous analysis, Canada produce good chocolate while Venezuela and Peru are one of the origins of top cocao Beans."
      ],
      "metadata": {
        "id": "3s9Dmq96fMko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for loc in df['company_location'].unique():\n",
        "    subset = df[df['company_location'] == loc]\n",
        "    plt.scatter(subset['cocoa_p'], subset['rating'], label=loc, alpha=0.5)\n",
        "\n",
        "plt.xlabel('Cocoa Percent(%)')\n",
        "plt.ylabel('Chocolate Bar Rating')\n",
        "plt.title('Scatter plot of Cocoa Percent vs Chocolate Bar Rating')\n",
        "plt.legend(title='Location', loc='center left', bbox_to_anchor=(1, 0.5), fontsize='small')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hgymQXeSjeLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this graph we can see when cocao=50% we have the highest average rating. but the case is not persuasive enough. Consider the sample sizes into account, 70% cocao bar still will be the best choice. Moreover, any chocolate bars from 65% - 75% percent cocao looks pretty good and 100% cocoa has lower ratings. In addition we can see that bars from France and Canda have high ratings."
      ],
      "metadata": {
        "id": "MPLjHdrd74Jt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to apply correlation plot and to run XGboost on our data we first would like to find all the categorial attributes.\n",
        "Then, we would like to convert all these features to one-hot encoding."
      ],
      "metadata": {
        "id": "et6j-H787c5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "# Apply label encoding to categorical features\n",
        "label_encoders = {}\n",
        "for feature in categorical_features:\n",
        "    label_encoders[feature] = LabelEncoder()\n",
        "    df[feature] = label_encoders[feature].fit_transform(df[feature])\n"
      ],
      "metadata": {
        "id": "spc1TMFD7c5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_without_weight = df.drop(columns=['weight'])\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df_without_weight.corr(), linewidths=0.1, vmax=1.0, square=True, cmap='coolwarm', linecolor='white', annot=True).set_title(\"Correlation Map\")"
      ],
      "metadata": {
        "id": "asFx3-757c5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see strong correlation between REF and review_year, so we will drop the REF coulmn."
      ],
      "metadata": {
        "id": "2wKShNJu7c5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['REF'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "9R8EB9Uj7c5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unbalace labels data\n"
      ],
      "metadata": {
        "id": "jAFgOeUUyasz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to categorize ratings\n",
        "def categorize_rating(rating):\n",
        "    if rating >= 0 and rating < 1:\n",
        "        return 1\n",
        "    elif rating >= 1 and rating < 2:\n",
        "        return 2\n",
        "    elif rating >= 2 and rating < 3:\n",
        "        return 3\n",
        "    elif rating >= 3 and rating < 4:\n",
        "        return 4\n",
        "    elif rating >= 4 and rating <= 5:\n",
        "        return 5\n",
        "    elif rating >= 5 and rating <= 6:\n",
        "        return 6\n",
        "\n",
        "\n",
        "# Apply the function to create the new categorical rating column\n",
        "df['categorical_rating'] = df['rating'].apply(categorize_rating)"
      ],
      "metadata": {
        "id": "CcblqopRyeTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "count the value of each categorial_rating"
      ],
      "metadata": {
        "id": "WjOUqZlCzNxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['categorical_rating'].value_counts()"
      ],
      "metadata": {
        "id": "7Djx04vizU3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the labels are unbalced so we will need to multiply samples with low count of labels."
      ],
      "metadata": {
        "id": "hMLX71R1z8m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the count of samples for each label\n",
        "label_counts = df['categorical_rating'].value_counts()\n",
        "\n",
        "# Determine the maximum count of samples for a label\n",
        "max_count = label_counts.max()\n",
        "\n",
        "# Initialize an empty list to store resampled DataFrames\n",
        "resampled_dfs = []\n",
        "\n",
        "# Iterate over each label\n",
        "for label, count in label_counts.items():\n",
        "    # Calculate the number of samples to resample\n",
        "    if count < max_count:\n",
        "        # Resample to match the count of the label with the maximum count\n",
        "        resampled_df = resample(df[df['categorical_rating'] == label],\n",
        "                                replace=True,\n",
        "                                n_samples=max_count - count,\n",
        "                                random_state=42)\n",
        "        # Append the resampled DataFrame to the list\n",
        "        resampled_dfs.append(resampled_df)\n",
        "\n",
        "# Concatenate the original DataFrame with the resampled DataFrames\n",
        "balanced_df = pd.concat([df] + resampled_dfs)\n",
        "\n",
        "# Shuffle the rows in the balanced DataFrame\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42)\n",
        "balanced_df['categorical_rating'].value_counts()"
      ],
      "metadata": {
        "id": "5-p892Bu0XPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning balanced df to origin df\n",
        "df = balanced_df"
      ],
      "metadata": {
        "id": "pRguWFwI1wLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oversampling, is one common method to balance imbalanced datasets. It involves randomly duplicating samples from the minority classes until the class distribution is balanced. This is a naive appoch and later on we will do other way of oversampling with noise in order to avoid overfitting"
      ],
      "metadata": {
        "id": "a-LBE-HZ1xpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outliers**\n",
        "Outliers can significantly affect the performance of your machine learning model. They can distort the overall distribution of the data, leading to biased model estimates and poor generalization to new data.\n",
        "They can disproportionately influence the model's coefficients, leading to inaccurate predictions."
      ],
      "metadata": {
        "id": "y1bodpFwJ9QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.mean()"
      ],
      "metadata": {
        "id": "CN8FPAckNkUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've decided to exclude the 'weight' and 'ratings' columns from the outliers calculation. This decision was made to avoid disregarding samples with uncommon ratings that are still relevant for prediction. The 'weight' feature, which is normally set to 1 for all samples except those that have been split, is not considered in the outliers calculation. Split samples have a weight less than 1, as explained earlier. Therefore, the 'weight' feature should not influence the identification of outliers, ensuring that split samples are not mistakenly labeled as outliers. It's worth noting that we split samples ourselves to handle cases where one feature contained multiple values. This was done to ensure that each feature had only one value per sample, simplifying the analysis."
      ],
      "metadata": {
        "id": "E4G8SmNeM9gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_detaction(df):\n",
        "  # Exclude 'weight','rating' columns from outlier detection\n",
        "  columns_to_exclude = ['weight','rating']\n",
        "\n",
        "  # Calculate z-scores for each column excluding specified columns\n",
        "  z_scores = df.drop(columns=columns_to_exclude).apply(lambda x: np.abs((x - x.mean()) / x.std()))\n",
        "\n",
        "  # Set a threshold for outlier detection (e.g., z-score > 3)\n",
        "  threshold = 3\n",
        "  outliers = df[(z_scores > threshold).any(axis=1)]\n",
        "\n",
        "  # Filter outliers from the DataFrame while including the dropped columns\n",
        "  filtered_df = df.drop(outliers.index)\n",
        "\n",
        "  print(\"Original DataFrame:\")\n",
        "  print(df.shape)\n",
        "  print(\"\\nFiltered DataFrame:\")\n",
        "  print(filtered_df.shape)\n",
        "\n",
        "  return filtered_df, outliers"
      ],
      "metadata": {
        "id": "FC6BTeHHLKeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A threshold of 3 standard deviations from the mean (z-score > 3) is often used, as it covers about 99.7% of the data in a normal distribution."
      ],
      "metadata": {
        "id": "J1U4-Y6YMPhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_filtered_df, outliers = outlier_detaction(df)\n",
        "print(f'Number of outliers: {len(outliers)}')"
      ],
      "metadata": {
        "id": "vWKDpc0OE8E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning balanced filtered df to origin df\n",
        "df = balanced_filtered_df"
      ],
      "metadata": {
        "id": "tbtd2quj3tdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Missing value analyze** -\n",
        "Handaling missing values in data set\n"
      ],
      "metadata": {
        "id": "eXTF5YMycD4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we fill the missing value in bean_type column accroding to our insight, we'll split our data to train and test so that information from the test set wont be taken into consideration when training."
      ],
      "metadata": {
        "id": "VFbcprvAFwnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we would separte our samples from the label we want to predict.\n",
        "Our label is 'categorical_rating'.\n"
      ],
      "metadata": {
        "id": "K7daTF2XC4a9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_processing(df):\n",
        "  # Map labels to start from 0\n",
        "  min_label = min(df['categorical_rating'])\n",
        "  df['categorical_rating'] = df['categorical_rating'] - min_label\n",
        "  y = df['categorical_rating']\n",
        "\n",
        "  # Separate features and labels\n",
        "  X = df.drop(['categorical_rating', 'rating'], axis=1)\n",
        "  y.value_counts()\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "ycWORtzDD2qR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X, y = label_processing(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)"
      ],
      "metadata": {
        "id": "-Pgt9tx40ELG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handaling missing values in train set"
      ],
      "metadata": {
        "id": "KhIE0gZi1Ezc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the mapping for a specific categorical feature\n",
        "def print_mapping(feature_name):\n",
        "  if feature_name in label_encoders:\n",
        "      mapping = dict(zip(label_encoders[feature_name].classes_, label_encoders[feature_name].transform(label_encoders[feature_name].classes_)))\n",
        "      print(mapping)"
      ],
      "metadata": {
        "id": "mHis6Gkr_jFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_mapping('bean_type')"
      ],
      "metadata": {
        "id": "Y_q4OfqWA9BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the encoder that the numeric values for 'Blend', '\\xa0' and nan are 4, 40 and 41 respectively."
      ],
      "metadata": {
        "id": "CGMBC_qp_3_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "X_train['bean_type'] = X_train['bean_type'].replace('\\xa0', \"Blend\")\n",
        "X_train['bean_type'] = X_train['bean_type'].replace('nan', \"Blend\")\n",
        "X_train['bean_type'].value_counts()\n",
        "\n",
        "The code above is the same as the following code but instead categorial values we have nomeric values:\n",
        "\"\"\"\n",
        "X_train['bean_type'] = X_train['bean_type'].replace(40, 4)\n",
        "X_train['bean_type'] = X_train['bean_type'].replace(41, 4)\n",
        "X_train['bean_type'].value_counts()\n"
      ],
      "metadata": {
        "id": "_s04xNWcl2-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace empty strings in 'bean_origin' column with 'Venezuela' which is the most common bean_origin"
      ],
      "metadata": {
        "id": "Ac44CKd9usy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_mapping('bean_origin')"
      ],
      "metadata": {
        "id": "7aDS1gfsBE1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the mapping- 'Venezuela': 61, 'nan': 65 and ' ': 0.\n"
      ],
      "metadata": {
        "id": "QBWcSX2CBmHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "X_train['bean_origin'] = X_train['bean_origin'].replace(' ', \"Venezuela\")\n",
        "# Replace NaN values in 'bean_origin' column with 'Venezuela'\n",
        "X_train['bean_origin']=  X_train['bean_origin'].replace(\"nan\", \"Venezuela\")\n",
        "X_train['bean_origin'].value_counts()\n",
        "\n",
        "The code above is the same as the following code but instead categorial values we have nomeric values:\n",
        "\"\"\"\n",
        "\n",
        "X_train['bean_origin'] = X_train['bean_origin'].replace(0, 61)\n",
        "# Replace NaN values in 'bean_origin' column with 'Venezuela'\n",
        "X_train['bean_origin']=  X_train['bean_origin'].replace(65, 61)\n",
        "X_train['bean_origin'].value_counts()"
      ],
      "metadata": {
        "id": "QEsCzdXQuprf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basic ML Pipeline - XGBoost**"
      ],
      "metadata": {
        "id": "-oo41zC5BzIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost classifier is trained on the training data (X_train and y_train) and used to make predictions on the test data (X_test). Finally, the accuracy of the model is calculated by comparing the predicted labels (y_pred) with the actual labels (y_test)."
      ],
      "metadata": {
        "id": "Rlzt6KS4EKE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, in the XGBoost algorithm, we aim to consider the 'weights' feature of samples to ensure that samples with lower weights have less impact compared to samples with a weight of 1. This approach is important because we want the split samples to represent a fraction of the original sample, reflecting their relative importance in the analysis."
      ],
      "metadata": {
        "id": "pSXsohvkHAUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_XGboost(X_train, y_train, X_test, y_test):\n",
        "\n",
        "  # Create an XGBoost classifier\n",
        "  clf = xgb.XGBClassifier()\n",
        "\n",
        "  # Convert weight to sample weights\n",
        "  sample_weights = np.array(X_train['weight'])\n",
        "\n",
        "  # Train the classifier with sample weights\n",
        "  model= clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  # # Map predictions back to original labels\n",
        "  # y_pred_original = y_pred + min_label\n",
        "\n",
        "  # Calculate accuracy\n",
        "  y_test = y_test.to_numpy()\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(\"Accuracy without cross-validation\", accuracy)\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "8oRWtrC7EI9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation metric:  Accuracy is a simple and intuitive metric that measures overall correctness. It's suitable when the class distribution is roughly balanced and there is no significant cost difference between false positives and false negatives like in our case. we add  confusion matrix to evaluate our performance because it provides a tabular summary of the number of correct and incorrect predictions made by a classifier for each class. It's useful for understanding the performance of the classifier in more detail.\n",
        "In addition we add statisitics mesurments of\n",
        "Precision: Proportion of true positives among positive predictions, crucial for avoiding false positives.\n",
        "Recall: Ability to capture actual positives, important for identifying loan defaults.\n",
        "F1-score: Harmonic mean of precision and recall, providing a balanced assessment.\n",
        "Now, we will perfome 10-fold cross validation"
      ],
      "metadata": {
        "id": "RFjAp8SDWPyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def ten_fold_cross_validation(X, y, dataset, clf, matrix_print=True):\n",
        "    # Define the number of folds for k-fold cross-validation\n",
        "    n_splits = 10\n",
        "\n",
        "    # Initialize lists to store evaluation scores for each fold\n",
        "    accuracy_scores = []\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "\n",
        "    # Initialize a list to store confusion matrices for each fold\n",
        "    conf_matrices = []\n",
        "\n",
        "    # Define the cross-validation strategy\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    # Perform k-fold cross-validation\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Train the classifier\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = clf.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation scores and append to lists\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
        "        recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
        "        f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "        # Calculate confusion matrix and append to list\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        conf_matrices.append(conf_matrix)\n",
        "\n",
        "    # Calculate and print the mean evaluation scores across all folds\n",
        "    mean_accuracy = np.mean(accuracy_scores)\n",
        "    mean_precision = np.mean(precision_scores)\n",
        "    mean_recall = np.mean(recall_scores)\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "    print(\"Mean Accuracy:\", mean_accuracy)\n",
        "    print(\"Mean Precision:\", mean_precision)\n",
        "    print(\"Mean Recall:\", mean_recall)\n",
        "    print(\"Mean F1-score:\", mean_f1)\n",
        "\n",
        "    if not matrix_print:\n",
        "        return\n",
        "\n",
        "    # Ensure all confusion matrices have the same shape\n",
        "    max_shape = max(matrix.shape for matrix in conf_matrices)\n",
        "    conf_matrices = [np.pad(matrix, ((0, max_shape[0] - matrix.shape[0]), (0, max_shape[1] - matrix.shape[1])), mode='constant', constant_values=0) for matrix in conf_matrices]\n",
        "\n",
        "    # Convert conf_matrices to numpy array\n",
        "    conf_matrices = np.array(conf_matrices)\n",
        "\n",
        "    # Calculate the mean of all confusion matrices\n",
        "    average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n",
        "    # Plot average confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(average_conf_matrix.astype(int), annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=range(0, 4), yticklabels=range(0, 4))\n",
        "    plt.title(f'Average Confusion Matrix - {dataset}')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.ylabel('True label')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1889q_VtJiCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def ten_fold_cross_validation(X, y, dataset, clf, matrix_print=True):\n",
        "#   # Define the number of folds for k-fold cross-validation\n",
        "#   n_splits = 10\n",
        "\n",
        "#   # Initialize a list to store accuracy scores for each fold\n",
        "#   accuracy_scores = []\n",
        "\n",
        "#   # Initialize a list to store confusion matrices for each fold\n",
        "#   conf_matrices = []\n",
        "\n",
        "#   # Define the cross-validation strategy\n",
        "#   kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "#   # Perform k-fold cross-validation\n",
        "#   for train_index, test_index in kf.split(X):\n",
        "#       X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "#       y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "#       # # Create an XGBoost classifier\n",
        "#       # clf = xgb.XGBClassifier()\n",
        "\n",
        "#       # Convert weight to sample weights\n",
        "#       sample_weights = np.array(X_train['weight'])\n",
        "\n",
        "#       # Train the classifier with sample weights\n",
        "#       clf.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "#       # Make predictions\n",
        "#       y_pred = clf.predict(X_test)\n",
        "\n",
        "#       # Map predictions back to original labels\n",
        "#       # y_pred_original = y_pred + min_label\n",
        "\n",
        "#       # Calculate accuracy and append to list\n",
        "#       accuracy = accuracy_score(y_test, y_pred)\n",
        "#       accuracy_scores.append(accuracy)\n",
        "\n",
        "#       # Calculate confusion matrix and append to list\n",
        "#       conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "#       conf_matrices.append(conf_matrix)\n",
        "\n",
        "\n",
        "#   # Calculate and print the mean accuracy across all folds\n",
        "#   mean_accuracy = np.mean(accuracy_scores)\n",
        "#   print(\"Mean Accuracy:\", mean_accuracy)\n",
        "\n",
        "#   if not matrix_print:\n",
        "#     return\n",
        "#   # Ensure all confusion matrices have the same shape\n",
        "#   max_shape = max(matrix.shape for matrix in conf_matrices)\n",
        "#   conf_matrices = [np.pad(matrix, ((0, max_shape[0] - matrix.shape[0]), (0, max_shape[1] - matrix.shape[1])), mode='constant', constant_values=0) for matrix in conf_matrices]\n",
        "\n",
        "#   # Convert conf_matrices to numpy array\n",
        "#   conf_matrices = np.array(conf_matrices)\n",
        "\n",
        "#   # Calculate the mean of all confusion matrices\n",
        "#   average_conf_matrix = np.mean(conf_matrices, axis=0)\n",
        "\n",
        "#   # Plot average confusion matrix\n",
        "#   plt.figure(figsize=(8, 6))\n",
        "#   sns.heatmap(average_conf_matrix.astype(int), annot=True, fmt='d', cmap='Blues',\n",
        "#               xticklabels=range(0, 4), yticklabels=range(0, 4))\n",
        "#   plt.title(f'Average Confusion Matrix - {dataset}')\n",
        "#   plt.xlabel('Predicted label')\n",
        "#   plt.ylabel('True label')\n",
        "#   plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "JAJ9vJ8UWN57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to evaluate our XGBOOST performance on our balanced filtered data."
      ],
      "metadata": {
        "id": "vtAly8B08HiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = perform_XGboost(X_train, y_train, X_test, y_test)\n",
        "ten_fold_cross_validation(X_train, y_train, 'Balanced - filtered', model)\n"
      ],
      "metadata": {
        "id": "GLmdkSTN_hwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Since we don't have a significant distinction between different types of mistakes (false positives and false negatives) in the classification problem, and all misclassifications are equally important, and we have balanced our dataset, then focusing on **accuracy** as the primary evaluation metric may indeed be appropriate."
      ],
      "metadata": {
        "id": "cqXhq_hARnQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Explain for our results**:\n",
        "Before the first submission we ran the XGboost algorithm and got Test Accuracy: 0.79510556621881 Validation Accuracy: 0.9191750332201389. The results we got were on train set with the same distribution as test set since we handeled missing values before splitting the data. According to the note we got (that it is a better practice to analyse and impute missing values after splitting to train and test) we splitted the data set before filling the missing values. Thus, our model was trained on a data from a different distribution than the test data. Naturally, the performance of our model would be less accurate."
      ],
      "metadata": {
        "id": "8Dn56rXGHY9Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Improve our model**"
      ],
      "metadata": {
        "id": "glQZ0Iz7Ocmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature importance**"
      ],
      "metadata": {
        "id": "4i8dm_rPt9tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "for feature, importance in zip(X_train, list(feature_importances)):\n",
        "  print(f'{feature}: {importance}')"
      ],
      "metadata": {
        "id": "N1O9gbNDvMNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the lowest importance is the 'weight' feature but we need it for our calculation (since it represets the weight of each splitted sample as explain before). We will drop just 'bean_type' and check if it improves performance."
      ],
      "metadata": {
        "id": "71U_ohPI0ixV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_temp = X_train.drop(['bean_type'], axis=1)\n",
        "X_test_temp = X_test.drop(['bean_type'], axis=1)\n"
      ],
      "metadata": {
        "id": "NbbxEO4r1NrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = perform_XGboost(X_train_temp, y_train, X_test_temp, y_test)\n",
        "ten_fold_cross_validation(X_train_temp, y_train, 'Balanced - filtered', model)"
      ],
      "metadata": {
        "id": "w6DW0MTH2heb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our performance now is slightly better."
      ],
      "metadata": {
        "id": "k33RMaTv3sCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "for feature, importance in zip(X_train_temp, list(feature_importances)):\n",
        "  print(f'{feature}: {importance}')"
      ],
      "metadata": {
        "id": "SVkNesqq6Gi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_temp = X_train_temp.drop(['bean_origin'], axis=1)\n",
        "X_test_temp = X_test_temp.drop(['bean_origin'], axis=1)\n"
      ],
      "metadata": {
        "id": "qdGH4lx46TpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = perform_XGboost(X_train_temp, y_train, X_test_temp, y_test)\n",
        "ten_fold_cross_validation(X_train_temp, y_train, 'Balanced - filtered', model)"
      ],
      "metadata": {
        "id": "NJrxmaA76eUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**improve our ML model BY GBM**"
      ],
      "metadata": {
        "id": "vektkSc7780v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting Machines (GBM): GBM algorithms like CatBoost build trees sequentially, where each tree corrects errors made by the previous one, potentially leading to better overall performance."
      ],
      "metadata": {
        "id": "N56-Uo5yhU83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define CatBoost parameters\n",
        "catboost_params = {\n",
        "    'iterations': 100,                  # Number of boosting iterations\n",
        "    'learning_rate': 0.1,               # Learning rate\n",
        "    'depth': 6,                         # Depth of the trees\n",
        "    'loss_function': 'MultiClass',      # Loss function for multi-class classification\n",
        "    'eval_metric': 'Accuracy',          # Evaluation metric\n",
        "    'random_seed': 42\n",
        "     'verbose': False # Random seed for reproducibility\n",
        "}\n",
        "\n",
        "# Create CatBoost classifier\n",
        "catboost_model = CatBoostClassifier(**catboost_params)\n",
        "\n",
        "# Train the model\n",
        "catboost_model.fit(X_train_temp, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_catboost = catboost_model.predict(X_test_temp)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_catboost = accuracy_score(y_test, y_pred_catboost)\n",
        "print(\"Accuracy:\", accuracy_catboost)\n"
      ],
      "metadata": {
        "id": "WpKOqkrbhUXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got better results using XGBoost so we will try to do hyper parametrs tuning for XGBOOST model in order to improve the resultls."
      ],
      "metadata": {
        "id": "r5piB6MWjq6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyper-Parameter Tuning XGBOOST**"
      ],
      "metadata": {
        "id": "XWlXny8jh8Hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def perform_best_XGboost(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    # Create an XGBoost classifier\n",
        "    clf = xgb.XGBClassifier()\n",
        "\n",
        "    # Define hyperparameters grid\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 300],\n",
        "        'max_depth': [3, 5, 7, 10, 12],\n",
        "        'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "    }\n",
        "\n",
        "    # Convert weight to sample weights\n",
        "    sample_weights = np.array(X_train['weight'])\n",
        "\n",
        "    # Perform grid search\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "    # Get the best model from grid search\n",
        "    best_clf = grid_search.best_estimator_\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "    return best_clf,y_pred\n"
      ],
      "metadata": {
        "id": "6KzbXTYn8cAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model ,y_pred= perform_best_XGboost(X_train_temp, y_train, X_test_temp, y_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IgNkNJhO8FB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analyze the final model performance**"
      ],
      "metadata": {
        "id": "jngFbDRtS4OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using SHAP -  SHAP (SHapley Additive exPlanations) is a method used in machine learning for understanding the output of black-box models. It provides explanations for individual predictions by attributing the prediction outcome to different features in the input data. SHAP values assign each feature an importance value for a particular prediction."
      ],
      "metadata": {
        "id": "f3MCaLkLu7r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating SHAP values"
      ],
      "metadata": {
        "id": "FUtjKK4MVo8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "explainer = shap.Explainer(model, X_train_temp)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values = explainer(X_train_temp)\n"
      ],
      "metadata": {
        "id": "uRWbGLO6q6fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(shap_values)"
      ],
      "metadata": {
        "id": "bMk94wDg8EVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we have multiclass we we visualize the shap value manually, firstly, we generate waterfall plots for the SHAP values of a single sample. Considering only the SHAP values for individual features across different classes."
      ],
      "metadata": {
        "id": "ogvtN1ZcvIkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.waterfall(shap_values[0, : ,0])\n",
        "shap.plots.waterfall(shap_values[0, : ,1])\n",
        "shap.plots.waterfall(shap_values[0, : ,2])\n",
        "shap.plots.waterfall(shap_values[0, : ,3])"
      ],
      "metadata": {
        "id": "1ACQ83jSvHs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see the shap plot for each class, the improtance of features across classes. Let's visualize the mean SHAP values across all samples"
      ],
      "metadata": {
        "id": "DCamkbckCl6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_0=np.mean(np.abs(shap_values.values[:,:,0]),axis=0)\n",
        "mean_1=np.mean(np.abs(shap_values.values[:,:,1]),axis=0)\n",
        "mean_2=np.mean(np.abs(shap_values.values[:,:,2]),axis=0)\n",
        "mean_3=np.mean(np.abs(shap_values.values[:,:,3]),axis=0)"
      ],
      "metadata": {
        "id": "dljIV33-ACx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the result"
      ],
      "metadata": {
        "id": "0YSL0YCmGp7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot mean absolute SHAP values for each feature\n",
        "num_features = len(mean_0)\n",
        "feature_names = X_train_temp.columns  # Assuming X_train_temp is a DataFrame with feature names\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "index = np.arange(num_features)\n",
        "bar_width = 0.2\n",
        "\n",
        "opacity = 0.6\n",
        "error_config = {'ecolor': '0.3'}\n",
        "\n",
        "bar0 = ax.bar(index, mean_0, bar_width, alpha=opacity, color='b', label='rate_0')\n",
        "bar1 = ax.bar(index + bar_width, mean_1, bar_width, alpha=opacity, color='r', label='rate 1')\n",
        "bar2 = ax.bar(index + 2 * bar_width, mean_2, bar_width, alpha=opacity, color='g', label='rate 2')\n",
        "bar3 = ax.bar(index + 3 * bar_width, mean_3, bar_width, alpha=opacity, color='y', label='rate 3')\n",
        "\n",
        "ax.set_xlabel('Features')\n",
        "ax.set_ylabel('Mean Absolute SHAP Values')\n",
        "ax.set_title('Mean Absolute SHAP Values for Each Feature Across Different Classes')\n",
        "ax.set_xticks(index + 1.5 * bar_width)\n",
        "ax.set_xticklabels(feature_names)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i3nhNsgzBJzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot we can see the mean shap value accross the featuresfor each class. For example we can see that for class-rate_0 there is high mean shap with cocoa_p feature.  "
      ],
      "metadata": {
        "id": "aO3T2IBYEgNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Error Analyze:\n",
        "This could indicate areas where the model needs improvement, such as feature engineering, data preprocessing, or model tuning."
      ],
      "metadata": {
        "id": "upslbAMWkEU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_predictions = X_test_temp[y_test != y_pred]\n",
        "incorrect_indices = [i for i in range(len(y_test)) if y_test.iloc[i] != y_pred[i]]\n",
        "\n",
        "\n",
        "shap.plots.waterfall(shap_values[incorrect_indices[0], : ,0])\n",
        "shap.plots.waterfall(shap_values[incorrect_indices[0], : ,1])\n",
        "shap.plots.waterfall(shap_values[incorrect_indices[0], : ,2])\n",
        "shap.plots.waterfall(shap_values[incorrect_indices[0], : ,3])\n"
      ],
      "metadata": {
        "id": "LNJn8jX7kGvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't see a pattern that caused the error. We thing in out case that since the dataset is small the model is underfitted."
      ],
      "metadata": {
        "id": "hVPkg47y6h2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aimed to enhance our machine learning model by incorporating feature selection and hyperparameter tuning. Our initial model was built on a meticulously preprocessed dataset, where we balanced the classes, removed outliers, and conducted extensive feature engineering. However, we suspect that the relatively small size of our dataset may have limited our model's performance. Despite these challenges, We tried to improve the basic ML algorithm using feature selectiom, and hyper parameter tunining and got small improvment."
      ],
      "metadata": {
        "id": "fEG1lCwr7Etk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclustion**\n",
        "We've explored numerous notebooks dedicated to this dataset, drawing inspiration from others' exploratory data analyses (EDAs). However, we've enriched our pipeline with crucial steps tailored to our specific needs. Firstly, during the preprocessing phase, we delved into feature engineering. Given the inconsistent *values* in certain columns of the dataset, we meticulously handled outliers and balanced classes by introducing a weight column. We pruned uninformative columns and addressed missing values by thoroughly understanding the data and inferring relevant values. Each column's meaning was carefully interpreted, and missing values were imputed with the most plausible values, enhancing the overall robustness of our preprocessing pipeline."
      ],
      "metadata": {
        "id": "Cxgvvvri8TZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **references**\n",
        "NOTEBOOK FOR ANALYZE DATASETS-\n",
        "https://www.kaggle.com/code/viannaandresouza/eda-chocolate-bar-ratings-analysis-statistic\n",
        "https://www.kaggle.com/code/noderaider/chocolate-bar-ratings-report\n",
        "https://www.kaggle.com/code/tibhar940/chocolate-bar-ratings-python-eda-dataviz\n",
        "https://www.kaggle.com/code/bansalvishesh/eda-on-chocolate-dataset\n",
        "https://www.kaggle.com/code/iamyajat/eda-and-cleaning-chocolate-ratings#EDA\n",
        "https://www.kaggle.com/code/sharanya02/exploring-chocolate-bar-ratings#Categorizing-chocolate-bars-based-on-their-rating\n",
        "\n",
        "ADDITIONAL WEBSITWS WE USE-\n",
        "https://xgboost.readthedocs.io/en/stable/\n",
        "https://shap.readthedocs.io/en/latest/\n"
      ],
      "metadata": {
        "id": "ZtCf_5ivkgGQ"
      }
    }
  ]
}